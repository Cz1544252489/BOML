
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml" lang="Python">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>Extensible Modules &#8212; BOML 0.1.0 documentation</title>
    <link rel="stylesheet" href="_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '0.1.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Related Papers" href="references.html" />
    <link rel="prev" title="Core Built-in Functions" href="built_in.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head>
  <body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="extensible-modules">
<h1>Extensible Modules<a class="headerlink" href="#extensible-modules" title="Permalink to this headline">¶</a></h1>
<ul>
<li><dl class="first docutils">
<dt>Extensible Base Calsses and Modules</dt>
<dd><ol class="first last arabic">
<li><p class="first">BOMLNet</p>
<ul>
<li><p class="first">Aliases：</p>
<blockquote>
<div><ul class="simple">
<li>boml.networks.BOMLNet</li>
</ul>
</div></blockquote>
</li>
<li><p class="first">Methods to be overridden:</p>
<blockquote>
<div><ul>
<li><dl class="first docutils">
<dt>forward()：</dt>
<dd><p class="first last">It uses defined convolutional neural networks with initial input</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>re_forward(new_input):</dt>
<dd><p class="first last">It reuses defined convolutional with new input and update the output results</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>create_outer_parameters():</dt>
<dd><p class="first">This method creates parameters of upper level problems, and adds them to define collections called <cite>METAPARAMETERS</cite></p>
<ul class="last simple">
<li>Args:
- var_collections: collections to restore meta parameters created in the so called scope</li>
<li>Returns: dictionary that indexes the outer parameters</li>
</ul>
</dd>
</dl>
</li>
<li><p class="first">create_model_parameters():</p>
<blockquote>
<div><p>This method creates model parameters of upper level problems like <cite>T layer</cite> or <cite>Warp layer</cite> , and adds them to define collections called <cite>METAPARAMETERS</cite>.</p>
</div></blockquote>
</li>
</ul>
</div></blockquote>
</li>
<li><p class="first">Utility functions:</p>
<blockquote>
<div><ul>
<li><p class="first">get_conv_weight(boml_net, layer, initializer):</p>
<blockquote>
<div><ul class="simple">
<li>Args:
- boml_net: initialized instance of BOMLNet
- layer: int32, the layer-th weight of convolutional block to be created
- initializer: the tensorflow initializer used to initialize the filters</li>
</ul>
</div></blockquote>
<p>-Returns: created parameter</p>
</li>
<li><p class="first">get_bias_weight(boml_net, layer, initializer):</p>
<blockquote>
<div><ul class="simple">
<li>Args:<ul>
<li>boml_net: initialized instance of BOMLNet</li>
<li>layer: int32, the layer-th bias of convolutional block to be created</li>
<li>initializer: the tensorflow initializer used to initialize the bias</li>
</ul>
</li>
<li>Returns: created parameter</li>
</ul>
</div></blockquote>
</li>
<li><p class="first">get_identity(dim, name, conv=True):</p>
<blockquote>
<div><ul class="simple">
<li>Args:<ul>
<li>dim: the dimension of identity metrix</li>
<li>name: name to initialize the metrix</li>
<li>conv: BOOLEAN , whether initialize the metrix or initialize the real value, default to be True</li>
</ul>
</li>
<li>Returns: the created parameter</li>
</ul>
</div></blockquote>
</li>
<li><p class="first">conv_block(boml_net, cweight, bweight):</p>
<blockquote>
<div><p>It uses defined convolutional weight and bias with current ouput of boml_net</p>
<blockquote>
<div><ul class="simple">
<li>Args:
- boml_net: initialized instance of BOMLNet
- cweight: parameter of convolutional filter
- bweight: parameter of bias for convolutional neural networks</li>
</ul>
</div></blockquote>
</div></blockquote>
</li>
<li><p class="first">conb_block_t(boml_net, conv_weight, conv_bias, zweight):</p>
<blockquote>
<div><p>uses defined convolutional weight, bias, and weights of t layer  with current ouput of boml_net</p>
<blockquote>
<div><ul class="simple">
<li>Args:<ul>
<li>boml_net: initialized instance of BOMLNet</li>
<li>conv_weight: parameter of convolution filter for convolutional neural networks</li>
<li>conv_bias: parameter of bias for convolutional neural networks</li>
<li>zweight: parameter of convolution filter for T-layer</li>
</ul>
</li>
</ul>
</div></blockquote>
</div></blockquote>
</li>
<li><p class="first">conv_block_warp(boml_net, cweight, bweight, zweight, zbias):</p>
<p>uses defined convolutional weight, bias and filters of warp layer  with current ouput of boml_net</p>
<blockquote>
<div><ul class="simple">
<li>Args:<ul>
<li>boml_net: initialized instance of BOMLNet</li>
<li>cweight: parameter of convolution filter for convolutional neural networks</li>
<li>bweight: parameter of bias for convolutional neural networks</li>
<li>zweight: parameter of convolution filter for Warp-layer</li>
<li>zbias: parameter of bias for Warp-layer</li>
</ul>
</li>
</ul>
</div></blockquote>
</li>
</ul>
</div></blockquote>
</li>
</ul>
</li>
<li><p class="first">BOMLInnerGrad</p>
<ul>
<li><p class="first">Aliases:</p>
<blockquote>
<div><ul class="simple">
<li>boml.LLProblem.BOMLInnerGrad</li>
</ul>
</div></blockquote>
</li>
<li><p class="first">Methods to be overridden:</p>
<blockquote>
<div><ul class="simple">
<li>compute_gradients( boml_opt, loss_inner, loss_outer=None, inner_method=None, param_dict=OrderedDict(), var_list=None, **inner_kargs):</li>
</ul>
<p>The method delivers equivalent functionality to the method called compute_gradients() in <cite>tf.train.Optimizer</cite>.</p>
<blockquote>
<div><ul class="simple">
<li>Args:<ul>
<li>boml_opt: instance of boml.optimizer.BOMLOpt, which is automatically create by the method in <cite>boml.boml_optimizer.BOMLOptimizer</cite></li>
<li>loss_inner: inner objective, which could be passed by <cite>boml.boml_optimizer.BOMLOptimizer.ll_problem</cite> or called directly.</li>
<li>loss_outer: outer objective,which could be passed automatically by <cite>boml.boml_optimizer.BOMLOptimizer.ll_problem</cite>, or called directly</li>
<li>param_dict: automatically passed by 'boml.boml_optimizer.BOMLOptimizer.ll_problem'</li>
<li>var_list: list of lower level variables</li>
<li>inner_kargs: optional arguments, which are same as <cite>tf.train.Optimizer</cite></li>
</ul>
</li>
<li>Returns：self</li>
</ul>
</div></blockquote>
</div></blockquote>
</li>
<li><p class="first">Utility functions:</p>
<blockquote>
<div><ul>
<li><p class="first">apply_updates():</p>
<blockquote>
<div><p>Descent step, as returned by <cite>tf.train.Optimizer.apply_gradients</cite>.</p>
</div></blockquote>
</li>
<li><p class="first">initialization():</p>
<blockquote>
<div><p>list of operations that return the values of the state variables for this learning dynamics after the execution of the initialization operation. If an initial dynamics is set, then it also executed.</p>
</div></blockquote>
</li>
<li><p class="first">state():</p>
<blockquote>
<div><p>A generator for all the state variables (optimized variables and possibly auxiliary variables) being optimized.</p>
</div></blockquote>
</li>
</ul>
</div></blockquote>
</li>
</ul>
</li>
<li><p class="first">BOMLOuterGrad</p>
<ul>
<li><p class="first">Aliases:</p>
<blockquote>
<div><ul class="simple">
<li>boml.ul_problem.BOMLOuterGrad</li>
</ul>
</div></blockquote>
</li>
<li><p class="first">Methods to be overridden:</p>
<blockquote>
<div><ul>
<li><p class="first">compute_gradients(outer_objective, bml_inner_grad, meta_param=None):</p>
<blockquote>
<div><ul class="simple">
<li>Args:<ul>
<li>bml_inner_grad: OptimzerDict object resulting from the inner objective optimization.</li>
<li>outer_objective: A loss function for the outer parameters (scalar tensor)</li>
<li>meta_param: Optional list of outer parameters to consider. If not provided will get all variables in the hyperparameter collection in the current scope.</li>
</ul>
</li>
<li>Returns: list of meta parameters involved in the computation</li>
</ul>
</div></blockquote>
</li>
</ul>
<blockquote>
<div><ul>
<li><p class="first">apply_gradients( inner_objective_feed_dicts=None, outer_objective_feed_dicts=None, initializer_feed_dict=None, param_dict=OrderedDict(), train_batches=None, experiments= [], global_step=None, session=None, online=False, callback=None)</p>
<blockquote>
<div><ul class="simple">
<li>Args:<ul>
<li>inner_objective_feed_dicts: Optional feed dictionary for the inner objective</li>
<li><dl class="first docutils">
<dt>outer_objective_feed_dicts: Optional feed dictionary for the outer objective</dt>
<dd>(note that this is not used in ForwardHG since hypergradients are not
variables)</dd>
</dl>
</li>
<li>global_step: Optional global step for the optimization process</li>
<li>param_dict: dictionary of parameters passed by <cite>boml.boml_optimizer.BOMLOptimizer</cite></li>
<li>session: Optional session (otherwise will take the default session)</li>
<li>experiments: list of instances of <cite>Experiment</cite>, needed when Reptile Algorithm are implemented</li>
</ul>
</li>
</ul>
</div></blockquote>
</li>
</ul>
</div></blockquote>
</div></blockquote>
</li>
<li><p class="first">Utility functions:</p>
<blockquote>
<div><blockquote>
<div><ul>
<li><p class="first">hgrads_hvars( meta_param=None, aggregation_fn=None, gradient_clip=None):</p>
<blockquote>
<div><p>Method for getting outergradient and outer parameters as required by apply_gradient methods from tensorflow optimizer.</p>
<ul class="simple">
<li>Args：<ul>
<li>meta_param: Optional list of outer parameters to consider. If not provided will get all variables in the hyperparameter collection in the current scope.</li>
<li><dl class="first docutils">
<dt>aggregation_fn: Optional operation to aggregate multiple hypergradients (for the same hyperparameter),</dt>
<dd>by default reduce_mean</dd>
</dl>
</li>
<li>gradient_clip: Optional operation like clipping to be applied.</li>
</ul>
</li>
</ul>
</div></blockquote>
</li>
</ul>
</div></blockquote>
<ul>
<li><p class="first">initialization():</p>
<blockquote>
<div><p>Returns groups of operation that initializes the variables in the computational graph.</p>
</div></blockquote>
</li>
</ul>
<blockquote>
<div><ul>
<li><p class="first">state():</p>
<blockquote>
<div><p>The method returns current state values of lower level variables.</p>
</div></blockquote>
</li>
</ul>
</div></blockquote>
</div></blockquote>
</li>
</ul>
</li>
<li><p class="first">BOMLOpt</p>
<ul>
<li><p class="first">Aliases:</p>
<blockquote>
<div><ul class="simple">
<li>boml.optimizer.BOMLOpt</li>
</ul>
</div></blockquote>
</li>
<li><p class="first">Methods to be overridden:</p>
<blockquote>
<div><ul class="simple">
<li><dl class="first docutils">
<dt>minimize(loss_inner, var_list=None, global_step=None, gate_gradients=tf.train.Optimizer.GATE_OP,</dt>
<dd>aggregation_method=None, colocate_gradients_with_ops=False, name=None, grad_loss=None):<ul class="last">
<li>Returns: an <cite>bml_inner_grad</cite> object relative to this minimization, same as <cite>tf.train.Optimizer.minimize.</cite></li>
</ul>
</dd>
</dl>
</li>
</ul>
</div></blockquote>
</li>
<li><p class="first">Utility functions:</p>
<blockquote>
<div><ul>
<li><p class="first">learning_rate():</p>
<blockquote>
<div><ul class="simple">
<li>Returns: the step size of this BOMLOptimizer</li>
</ul>
</div></blockquote>
</li>
</ul>
</div></blockquote>
</li>
<li><p class="first">Utility Functions</p>
<blockquote>
<div><ul>
<li><p class="first">get_dafault_session():</p>
<blockquote>
<div><p>The method gets and returns the default tensorflow session</p>
</div></blockquote>
</li>
</ul>
</div></blockquote>
</li>
</ul>
</li>
</ol>
</dd>
</dl>
</li>
<li><p class="first">Utility Modules:</p>
<blockquote>
<div><ul class="simple">
<li>get_default_session():</li>
</ul>
<p>The method gets and returns the default tensorflow session</p>
<ul class="simple">
<li>BatchQueueMock():</li>
</ul>
<p>The class is responsible for generates batches of taskes and feed them into corresponding placeholders.</p>
<ul class="simple">
<li>cross_entropy(pred, label, method):</li>
</ul>
<p>It returns loss function that matches different methods in [MetaRepr,`MetaRper`]</p>
<ul class="simple">
<li>vectorize_all(var_list, name=None):</li>
</ul>
<p>The method vectorize the variables in the list named var_list with the given name</p>
<ul class="simple">
<li>remove_from_collectinon(key,*var_list):</li>
</ul>
<p>The method removes the variables in the var_list according to the given Graph key</p>
<ul class="simple">
<li>set_gpu():</li>
</ul>
<p>The method sets primary parameters of GPU configuration.</p>
</div></blockquote>
</li>
</ul>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper"><div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
      <li>Previous: <a href="built_in.html" title="previous chapter">Core Built-in Functions</a></li>
      <li>Next: <a href="references.html" title="next chapter">Related Papers</a></li>
  </ul></li>
</ul>
</div>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/extension.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <div><input type="text" name="q" /></div>
      <div><input type="submit" value="Go" /></div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2020, Yaohua Liu, Risheng Liu.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.6.3</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.10</a>
      
      |
      <a href="_sources/extension.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>